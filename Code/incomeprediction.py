# -*- coding: utf-8 -*-
"""IncomePrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XfieZauE2Rf2WWNYoQF4rubeJl4PTdxr
"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

"""# Data Exploration"""

columns = ['age','workclass','id','education','education_num','marital_status',
           'occupation','relationship','race','sex','capital_gain','capital_loss','hours_per_week','native_country','Class']
# Load the Training set (adult_data.data)
train = pd.read_csv('adult_data.data', header=None, names=columns, sep=' *, *')

# Load the Test set (adult_test.txt)
test = pd.read_csv('adult_test.txt', header=None, names=columns, skiprows=1, sep=' *, *')

train.head()

test.head()

train.describe()

train.info()

print('Train set shape', train.shape)
print('Test set shape', test.shape)

print('Train Data in %', (train.shape[0]/(train.shape[0]+test.shape[0])*100))
print('Test Data in %', (test.shape[0]/(train.shape[0]+test.shape[0])*100))

train.Class.value_counts()

test.Class.value_counts()

import seaborn as sns
sns.set(style="darkgrid")
ax = sns.countplot(x="Class", data=train)

train.age.unique(

import matplotlib.pyplot as plt

plt.rcParams['figure.figsize'] = [12, 8]
sns.set(style = 'whitegrid')

sns.distplot(train['age'], bins = 90, color = 'mediumslateblue')
plt.ylabel("Distribution", fontsize = 15)
plt.xlabel("Age", fontsize = 15)
plt.margins(x = 0)

print ("The maximum age is", train['age'].max())
print ("The minimum age is", train['age'].min())

train.native_country.value_counts()

test.workclass.value_counts()

import seaborn as sns

sns.countplot(y='workclass', hue='Class', data = train.select_dtypes(include=['object']))

train.education.unique()

train.education_num.unique()

edu = train.groupby(['education','education_num']).size().reset_index()

edu.sort_values(by ='education_num', ascending = True)

train.marital_status.value_counts()

train.occupation.value_counts()

import seaborn as sns

sns.countplot(y='occupation', hue='Class', data = train.select_dtypes(include=['object']))

sns.countplot(y='native_country', hue='Class', data = train.select_dtypes(include=['object']))

train.relationship.value_counts()

train.race.value_counts()

train.sex.value_counts()

train.capital_gain.describe()

train.capital_loss.describe()

train.hours_per_week.describe()

train.native_country.value_counts()

train.Class.value_counts()

test.Class.value_counts()

train.head(10)

# Distribution of Different Features of the Dataset
distribution = train.hist(edgecolor = 'black', linewidth = 1.2, color = 'c')
fig = plt.gcf()
fig.set_size_inches(8,8)
plt.show()

"""# Data Preprocessing"""

train.Class = train.Class.str.replace('<=50K', '0',  regex=False)
train.Class = train.Class.str.replace('>50K', '1', regex=False)
train.Class = train.Class.astype(int)

test.Class = test.Class.str.replace('<=50K.', '0',  regex=False)
test.Class = test.Class.str.replace('>50K.', '1', regex=False)
test.Class = test.Class.astype(int)

"""## Handling Missing Values

### Method 1: Using Logistic Regression
"""

'''
# Missing value chosen using Classification. (see notebook IncomePredication_MissingValWithModel)
train.workclass = train.workclass.str.replace('?','Private', regex=False)
train.occupation = train.occupation.str.replace('?','Craft-repair', regex=False)
train.native_country = train.native_country.str.replace('?',' United-States', regex=False)

test.workclass = test.workclass.str.replace('?','Private', regex=False)
test.occupation = test.occupation.str.replace('?','Craft-repair', regex=False)
test.native_country = test.native_country.str.replace('?',' United-States', regex=False)
'''

"""### Method 2: Dropping null values"""

# Missing value chosen using Classification. (see notebook IncomePredication_MissingValWithModel)
train.workclass.replace('?',np.nan, inplace=True)
train.occupation.replace('?',np.nan, inplace=True)
train.native_country.replace('?',np.nan, inplace=True)

test.workclass.replace('?',np.nan, inplace=True)
test.occupation.replace('?',np.nan, inplace=True)
test.native_country.replace('?',np.nan, inplace=True)

train = train.dropna()

train.shape

test = test.dropna()

"""## Outlier Detection"""

sns.boxplot(data = train, y = 'age')

sns.boxplot(data = train, y = 'hours_per_week')

"""## Feature Selection"""

import seaborn as sns
import matplotlib.pyplot as plt
# correlation matrix
corrmat = train.corr()
f, ax = plt.subplots(figsize=(8,8))
sns.set(font_scale=1)
sns.heatmap(corrmat,annot=True, square=True, fmt='.2f', vmax=.8);

ax = sns.countplot(train['marital_status'], hue=train['Class'])
ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha="right")
plt.tight_layout()

test.marital_status.value_counts()

train.marital_status = train.marital_status.str.replace('Widowed','single', regex=False)
train.marital_status = train.marital_status.str.replace('Divorced','single', regex=False)
train.marital_status = train.marital_status.str.replace('Separated','single', regex=False)
train.marital_status = train.marital_status.str.replace('Never-married','single', regex=False)
train.marital_status = train.marital_status.str.replace('Married-spouse-absent','Married', regex=False)
train.marital_status = train.marital_status.str.replace('Married-civ-spouse','Married', regex=False)
train.marital_status = train.marital_status.str.replace('Married-AF-spouse','Married', regex=False)

test.marital_status = test.marital_status.str.replace('Widowed','single', regex=False)
test.marital_status = test.marital_status.str.replace('Divorced','single', regex=False)
test.marital_status = test.marital_status.str.replace('Separated','single', regex=False)
test.marital_status = test.marital_status.str.replace('Never-married','single', regex=False)
test.marital_status = test.marital_status.str.replace('Married-spouse-absent','Married', regex=False)
test.marital_status = test.marital_status.str.replace('Married-civ-spouse','Married', regex=False)
test.marital_status = test.marital_status.str.replace('Married-AF-spouse','Married', regex=False)

"""##Categorical to Numeric

###One Hot encoding
"""

cat_cols = ['workclass','marital_status','occupation','relationship','race','sex','native_country']
num_cols = ['age', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week', 'Class']

#Train Data
final_train = train[cat_cols]
final_train = pd.get_dummies(final_train)
final_train = final_train.join(train[num_cols])

#Train Data
final_test = test[cat_cols]
final_test = pd.get_dummies(final_test)
final_test = final_test.join(test[num_cols])
#adding column 'native_country_Holand-Netherlands' because there is no record with 
#country 'Holand-Netherlands' in test set.
final_test['native_country_Holand-Netherlands'] = 0

print('Train set shape', final_train.shape)
print('Test set shape', final_test.shape)

"""## Normalization"""

from sklearn.preprocessing import MinMaxScaler

#Train Data
min_max_scaler = MinMaxScaler()
np_scaled_train = min_max_scaler.fit_transform(final_train)
data_norm_train= pd.DataFrame(np_scaled_train, columns = final_train.columns)
#data_norm.head()

#Test Data
min_max_scaler = MinMaxScaler()
np_scaled_test = min_max_scaler.fit_transform(final_test)
data_norm_test = pd.DataFrame(np_scaled_test, columns = final_test.columns)
#data_norm.head()

"""## Data Sampling

### SMOTE
"""

from imblearn.over_sampling import SMOTE 

sm = SMOTE(random_state=42)
train_smote, class_smote = sm.fit_sample(data_norm_train.drop('Class',axis=1), data_norm_train['Class'])

print('Train smote shape', train_smote.shape)
print('Train smote class shape', class_smote.shape)

"""#Utility Methods"""

from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_curve, roc_auc_score

def getEvaluationMetrics(y_test, y_pred, bool=False):
  
  classifierMetrics = {}
  
  # Accuracy
  accuracy = accuracy_score(y_test,y_pred)
  print('Accuracy :',accuracy)

  classifierMetrics['Accuracy'] = accuracy
  
  # Classification Report
  print(classification_report(y_test, y_pred, target_names=['<=50K', '>50K'], output_dict=bool))
  
  return classifierMetrics

def getConfusionMatrix(y_test, y_pred):
  # Confusion matrix
  mat = confusion_matrix(y_test, y_pred)
  cm = pd.DataFrame(mat)
  TP = cm.iloc[1,1] # True Positive - Predicted >50K Correctly
  TN = cm.iloc[0,0] # True Negative - Predicted <=50K Incorrectly
  FP = cm.iloc[0,1] # False Positive - Predicted >50K when it didn't rain
  FN = cm.iloc[1,0] # False Negative - Predicted <=50K when it did rain

  print('Sensitivity: {:.2%}'.format(TP/(FN+TP)))
  print('Specificity: {:.2%}'.format(TN/(FP+TN)))
  
  sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=True)
  plt.title('A confusion matrix showing the frequency of misclassifications by our classifier')
  plt.xlabel('true label')
  plt.ylabel('predicted label');
  plt.show()

def getROCcurve(y_test, y_prob_rain):
  fpr, tpr, thresholds = roc_curve(y_test,y_prob_rain[:,1])

  #ROC Curve
  fig,ax1 = plt.subplots(figsize=(6,4))
  ax1.plot(fpr, tpr,color='orange')
  ax1.legend(['ROC Curve'],loc=1)
  ax1.set_xlim([-0.005, 1.0])
  ax1.set_ylim([0,1])
  ax1.set_ylabel('True Positive Rate (Sensitivity)')
  ax1.set_xlabel('False Positive Rate \n(1 - Specificity)\n FP / (TN + FP)')
  ax1.set_title('ROC Curve for Income Prediction\n')

  plt.show()
  
  rf_auc = roc_auc_score(y_test,y_prob_rain[:,1])
  print('AUC Score:', rf_auc*100)
  return rf_auc*100

"""#Models"""

EvaluationMetrics = {}

#Train data
#Xtrain = data_norm_train.drop(columns='Class', axis=1)
#Ytrain = data_norm_train['Class']

Xtrain = train_smote
Ytrain = class_smote

#Test data
Xtest = data_norm_test.drop(columns='Class', axis=1)
Ytest = data_norm_test['Class']

print('Xtrain shape', Xtrain.shape)
print('Ytrain shape', Ytrain.shape)

print('Xtest shape', Xtest.shape)
print('Ytrain shape', Ytest.shape)

data_norm_train.shape

"""## Logistic Regression"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import StratifiedKFold

lr = LogisticRegression(random_state=0)
lr.fit(Xtrain, Ytrain)
Ypred = lr.predict(Xtest)

metrics = getEvaluationMetrics(Ytest,Ypred)
# Get the ROC Curve
auc = getROCcurve(Ytest, lr.predict_proba(Xtest))
# Get the Confusion Matrix
getConfusionMatrix(Ytest, Ypred)

metrics['AUC'] = auc

EvaluationMetrics['Logistic Regression'] = metrics

"""##Decision Tree"""

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier(random_state=0)
dt.fit(Xtrain, Ytrain)
Ypred = dt.predict(Xtest)

metrics = getEvaluationMetrics(Ytest,Ypred)
# Get the ROC Curve
auc = getROCcurve(Ytest, dt.predict_proba(Xtest))
# Get the Confusion Matrix
getConfusionMatrix(Ytest, Ypred)

metrics['AUC'] = auc

EvaluationMetrics['DecisionTreeClassifier'] = metrics

"""## K-means

### Elbow method
"""

'''
from sklearn.cluster import KMeans

distortions = []
K = range(1,18)
for k in K:
    kmeanModel = KMeans(n_clusters=k)
    kmeanModel.fit(Xtrain)
    #print(kmeanModel.inertia_)
    distortions.append(kmeanModel.inertia_)
'''

'''
import matplotlib.pyplot as plt

plt.figure(figsize=(10,6))
plt.plot(K, distortions, 'bx-')
plt.xlabel('k')
plt.ylabel('Distortion')
plt.title('The Elbow Method showing the optimal k')
plt.show()
'''

"""### Model"""

from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters=2)
kmeans.fit(Xtrain)
Ypred = kmeans.predict(Xtest)

metrics = getEvaluationMetrics(Ytest,Ypred)
# Get the ROC Curve
#auc = getROCcurve(Ytest, kmeans.predict_proba(Xtest))
# Get the Confusion Matrix
getConfusionMatrix(Ytest, Ypred)

#metrics['AUC'] = auc

EvaluationMetrics['Kmeans'] = metrics

'''
import matplotlib.pyplot as plt

centers = kmeans.cluster_centers_
plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5);
'''

"""## SVM"""

#from sklearn.svm import SVC

#svm = SVC(C=1.0, kernel='linear', degree=2, gamma='auto')
#svm.fit(Xtrain,Ytrain)

# Predicting the Class on validation dataset
#predictions_SVM = svm.predict(test_smote.drop('Class',axis=1))

# Use accuracy_score function to get the accuracy
#print("SVM Accuracy Score -> ",accuracy_score(predictions_SVM, test_smote['Class'])*100)

"""## RandomForestClassifier"""

from sklearn.ensemble import RandomForestClassifier

clf = RandomForestClassifier(n_estimators=100, random_state=24)
clf.fit(Xtrain,Ytrain)

Ypred = clf.predict(Xtest)

metrics = getEvaluationMetrics(Ytest,Ypred)
# Get the ROC Curve
auc = getROCcurve(Ytest, clf.predict_proba(Xtest))
# Get the Confusion Matrix
getConfusionMatrix(Ytest, Ypred)

metrics['AUC'] = auc

EvaluationMetrics['RandomForestClassifier'] = metrics

"""## Bagging"""

from sklearn.ensemble import BaggingClassifier

clf_bag = BaggingClassifier(DecisionTreeClassifier(), bootstrap_features = 'true',
                            warm_start = 'true', n_estimators=20)
clf_bag.fit(Xtrain,Ytrain)
Ypred = clf_bag.predict(Xtest)

metrics = getEvaluationMetrics(Ytest,Ypred)
# Get the ROC Curve
auc = getROCcurve(Ytest, clf.predict_proba(Xtest))
# Get the Confusion Matrix
getConfusionMatrix(Ytest, Ypred)

metrics['AUC'] = auc

EvaluationMetrics['BaggingClassifier'] = metrics

"""## AdaBoostClassifier"""

from sklearn.ensemble import AdaBoostClassifier

ada = AdaBoostClassifier(n_estimators=100, random_state=0)
ada.fit(Xtrain,Ytrain)
Ypred = ada.predict(Xtest)

metrics = getEvaluationMetrics(Ytest,Ypred)
# Get the ROC Curve
auc = getROCcurve(Ytest, clf.predict_proba(Xtest))
# Get the Confusion Matrix
getConfusionMatrix(Ytest, Ypred)

metrics['AUC'] = auc

EvaluationMetrics['AdaBoostClassifier'] = metrics

"""#Model Comparison"""

evaluationMetrics = pd.DataFrame(EvaluationMetrics)

evaluationMetrics.head(10).transpose()

from sklearn import model_selection

seed =7
models = []
models.append(('LR', LogisticRegression(random_state=0)))
models.append(('DT', DecisionTreeClassifier(random_state=0)))
#models.append(('KMeans', KMeans(n_clusters=2)))
models.append(('RandomForest', RandomForestClassifier(n_estimators=100, random_state=24)))
models.append(('Bagging', BaggingClassifier(DecisionTreeClassifier(), bootstrap_features = 'true',
                            warm_start = 'true', n_estimators=20)))
models.append(('AdaBoost', AdaBoostClassifier(n_estimators=100, random_state=0)))
# evaluate each model in turn
results = []
names = []
scoring = 'accuracy'
for name, model in models:
	kfold = model_selection.KFold(n_splits=10, random_state=seed)
	cv_results = model_selection.cross_val_score(model, Xtrain, Ytrain, cv=kfold, scoring=scoring)
	results.append(cv_results)
	names.append(name)
	msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
	print(msg)
# boxplot algorithm comparison
fig = plt.figure()
fig.suptitle('Algorithm Comparison')
ax = fig.add_subplot(111)
plt.boxplot(results)
ax.set_xticklabels(names)
plt.show()

